```{r cache = TRUE}
# K values for testing
k.test = c(1, seq(10,50, length.out = 9))

# Function for CV
do.chunk <- function(chunkid, folddef, Xdat, Ydat, k){
train = (folddef!=chunkid)
Xtr = Xdat[train,]
Ytr = Ydat[train]
Xvl = Xdat[!train,]
Yvl = Ydat[!train]
## get classifications for current training chunks
predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, k = k)
## get classifications for current test chunk
predYvl = knn(train = Xtr, test = Xvl, cl = Ytr, k = k)
# Returns a data fram of Training Error and Validation Error
data.frame(train.error = calc_error_rate(predYtr, Ytr),
val.error = calc_error_rate(predYvl, Yvl))
}

# Tibble of Each K value and it's Average Training and Test Errors
K_Errors <- tibble("K" = k.test, "AveTrnError" = NA, "AveTstError" = NA)

predictors <- select(trn.cl, -candidate)

for(i in 1:10){

temp <- plyr::ldply(1:10, do.chunk, folds,predictors, trn.cl$candidate, K_Errors$K[i])

K_Errors$AveTrnError[i] <- mean(temp[,1])
K_Errors$AveTstError[i] <- mean(temp[,2])
}

# Example Code for making Predictions Need to Graph 
# K vs both Errors before making decision
prediction.trn = knn(train = trn.cl[2:27], test = trn.cl[2:27], cl = trn.cl$candidate, k = 2)
#prediction.tst <- knn(train = trn.cl[2:27], test = tst.cl[2:27], cl = trn.cl$candidate, k = 2)
```

```{r}
# Plot shows that K = 15 is best balance of training and test error.
# Makes training set and test set predictions using k = 15
prediction.trn <- knn(train = trn.cl[2:27], test = trn.cl[2:27], cl = trn.cl$candidate, k = 15)
prediction.tst <- knn(train = trn.cl[2:27], test = tst.cl[2:27], cl = trn.cl$candidate, k = 15)

# Saves KNN results into records matrix
records[2,1] <- calc_error_rate(prediction.trn, trn.cl$candidate)
records[2,2] <- calc_error_rate(prediction.tst, tst.cl$candidate)
records
```

```{r}
# Melts columns for plotting
K_Errors_yax <- melt(K_Errors, id = "K")
# Renames observations for plot readability
names(K_Errors_yax)[2] <- "Legend"
levels(K_Errors_yax$Legend)<- c("Training Error", "Testing Error")


ggplot(K_Errors_yax, aes(x = K))+ ggtitle("KNN 10-Fold Cross Validation Training and Testing Error")+ ylab("Error Rate")+geom_smooth(aes(x = K,y = value, colour = Legend), se = F) + scale_color_manual(values = c("orange","blue"))
```
